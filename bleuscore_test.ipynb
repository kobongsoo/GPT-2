{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc88a04-6f06-4fd0-a3da-a1fb261ce9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../log/bwdataset_2022-05-12.log\n",
      "logfilepath:../log/qnadataset_2022-05-12.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "cuda:0\n",
      "logfilepath:../log/gpt2-bleu_2022-05-12.log\n"
     ]
    }
   ],
   "source": [
    "#================================================================\n",
    "# BLEU(Bilingual Evaluation Understudy) 측정 예\n",
    "#\n",
    "# => GPT-2와 같은 Language Model(text 생성)에서 성능 측정시 BLEU를 이용한다. \n",
    "# => BLEU는 기계번역 성능 측정 스코어로, 실제 번역 문장(references)과 모델이 생성한 문장(candidate)을 비교하여 스코어를 구한다\n",
    "# => BLUE 스코어는 0~1 임, 1이면 일치한 문장, 스코어가 높을수록 성능 좋은 것임\n",
    "# => NLTK에 bleu_score 라이브러리를 이용하면 됨\n",
    "#\n",
    "# =>자세한 내용은 https://wikidocs.net/31695 참조\n",
    "#\n",
    "#================================================================\n",
    "from myutils import GPU_info, seed_everything, mlogging, get_bleu_scores\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = GPU_info()\n",
    "print(device)\n",
    "\n",
    "#seed 설정\n",
    "seed_everything(222)\n",
    "\n",
    "#logging 설정\n",
    "logger =  mlogging(loggername=\"gpt2-bleu\", logfilename=\"../log/gpt2-bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706a1bad-2e85-4b27-91ec-400237a8d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
      "The class this function is called from is 'GPT2TokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '▁안녕', '하', '세', '요.', '▁한국어', '▁G', 'P', 'T', '-2', '▁입', '니다.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT-2 tokenizer, model 로딩 \n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast, GPT2TokenizerFast\n",
    "\n",
    "######################################################\n",
    "model_path='../model/gpt-2/kogpt-2-ft-0504/'\n",
    "######################################################\n",
    "\n",
    "# bos_token = </s> 인 이유는 => 보통 훈련된 모델들은 </s>를 시작 과 종료 토큰으로 모두 사용한다.\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_path,\n",
    "                                                   bos_token='</s>',\n",
    "                                                   eos_token='</s>',\n",
    "                                                   unk_token='<unk>',\n",
    "                                                   pad_token='<pad>',\n",
    "                                                   mask_token='<mask>')\n",
    "\n",
    "print(tokenizer.tokenize(\"<s>안녕하세요. 한국어 GPT-2 입니다.\"))\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "870f4d57-9f91-4d07-a780-d3be3e4c4016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bee015f5364dd8ba80876e987f9e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*input    : 이번 신제품 출시에 대한 *blue: 0.43012508513132625 *-1\n",
      "*reference: 이번 신제품 출시에 대한 시장의 반응은 어떤가요\n",
      "*candidate: 이번 신제품 출시에 대한 회의가 있었습니다\n",
      "\n",
      "*input    : 판매량이 지난번 제품보다 *blue: 5.775353993361614e-78 *-2\n",
      "*reference: 판매량이 지난번 제품보다 빠르게 늘고 있습니다\n",
      "*candidate: 판매량이 지난번 제품보다 많이 늘었는데  왜\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*input    : 그렇다면 공장에 연락해서 주문량을 더 *blue: 0.44632361378533286 *-3\n",
      "*reference: 그렇다면 공장에 연락해서 주문량을 더 늘려야겠네요\n",
      "*candidate: 그렇다면 공장에 연락해서 주문량을 더 늘릴 수 있도록 노력\n",
      "\n",
      "*input    : 네  제가 연락해서 주문량을 2배로 *blue: 0.44632361378533286 *-4\n",
      "*reference: 네  제가 연락해서 주문량을 2배로 늘리겠습니다\n",
      "*candidate: 네  제가 연락해서 주문량을 2배로 늘릴 수 있도록 하겠\n",
      "\n",
      "*input    : 지난 회의 마지막에 논의했던 안 *blue: 0.6147881529512643 *-5\n",
      "*reference: 지난 회의 마지막에 논의했던 안건을 다시 볼까요\n",
      "*candidate: 지난 회의 마지막에 논의했던 안건을 마무리하고 싶은데\n",
      "\n",
      "*input    : 그보다는 이번 주 새로운 주제가 더 *blue: 0.537284965911771 *-6\n",
      "*reference: 그보다는 이번 주 새로운 주제가 더 급한 것 같습니다\n",
      "*candidate: 그보다는 이번 주 새로운 주제가 더 많이 나와야 할 것\n",
      "\n",
      "*input    : 그럼 새로운 안건으로 *blue: 5.021333847570327e-78 *-7\n",
      "*reference: 그럼 새로운 안건으로 회의를 시작하도록 하죠\n",
      "*candidate: 그럼 새로운 안건으로 회의 일정을 잡아야 하는데\n",
      "\n",
      "*input    : 네  자료는 여러분의 앞에 미리 *blue: 1.0 *-8\n",
      "*reference: 네  자료는 여러분의 앞에 미리 준비되어 있습니다\n",
      "*candidate: 네  자료는 여러분의 앞에 미리 준비되어 있습니다\n",
      "\n",
      "*input    : 이번 주 금요일까지 2천개를 더 *blue: 0.5169731539571706 *-9\n",
      "*reference: 이번 주 금요일까지 2천개를 더 주문하라는 건가요\n",
      "*candidate: 이번 주 금요일까지 2천개를 더 주문할 수 있을까\n",
      "\n",
      "*input    : 네  시간이 조금 촉박하기는 *blue: 0.44632361378533286 *-10\n",
      "*reference: 네  시간이 조금 촉박하기는 하지만 가능해 보이는데요\n",
      "*candidate: 네  시간이 조금 촉박하기는 하지만 그래도 한 번 해\n",
      "\n",
      "*input    : 주문은 가능하지만  수령은 2달 정도 *blue: 0.5444460596606694 *-11\n",
      "*reference: 주문은 가능하지만  수령은 2달 정도 걸릴 것 같네요\n",
      "*candidate: 주문은 가능하지만  수령은 2달 정도 소요됩니다\n",
      "\n",
      "*input    : 이런  저희는 물건을 *blue: 4.603819786215014e-78 *-12\n",
      "*reference: 이런  저희는 물건을 최대한 빠르게 받고 싶어요\n",
      "*candidate: 이런  저희는 물건을 배송해드릴 때\n",
      "\n",
      "*input    : 사무용품이나 가구 중 가장 먼저 바꿔야 할 것은 *blue: 0.7598356856515925 *-13\n",
      "*reference: 사무용품이나 가구 중 가장 먼저 바꿔야 할 것은 뭐라고 생각하나요\n",
      "*candidate: 사무용품이나 가구 중 가장 먼저 바꿔야 할 것은 어떤 거예요\n",
      "\n",
      "*input    : 아무래도 컴퓨터가 아닐까요  *blue: 5.021333847570327e-78 *-14\n",
      "*reference: 아무래도 컴퓨터가 아닐까요  가장 많이 쓰니까요\n",
      "*candidate: 아무래도 컴퓨터가 아닐까요  아니면 다른 기계인가 봐\n",
      "\n",
      "*input    : 저는 모두가 같이 쓰는 회의실 책상을 먼저 *blue: 0.6548907866815301 *-15\n",
      "*reference: 저는 모두가 같이 쓰는 회의실 책상을 먼저 바꿔야 한다고 생각해요\n",
      "*candidate: 저는 모두가 같이 쓰는 회의실 책상을 먼저 가져다주세요\n",
      "\n",
      "*input    : 그럴 수도 있겠네요  회사에서 *blue: 0.41113361690051975 *-16\n",
      "*reference: 그럴 수도 있겠네요  회사에서 제일 오래되기도 했죠\n",
      "*candidate: 그럴 수도 있겠네요  회사에서 지원금을 받아서 신청했\n",
      "\n",
      "*input    : 오늘이나 내일 중에 본사에 가시는 *blue: 0.44632361378533286 *-17\n",
      "*reference: 오늘이나 내일 중에 본사에 가시는 분이 있나요\n",
      "*candidate: 오늘이나 내일 중에 본사에 가시는 게 좋을 것 같아요\n",
      "\n",
      "*input    : 제가 오늘 오후 5시쯤 본사에 *blue: 0.5169731539571706 *-18\n",
      "*reference: 제가 오늘 오후 5시쯤 본사에 가려고 했습니다\n",
      "*candidate: 제가 오늘 오후 5시쯤 본사에 도착할 것 같습니\n",
      "\n",
      "*input    : 그럼 오늘 회의 결과도 함께 가지고 *blue: 0.7013967267997694 *-19\n",
      "*reference: 그럼 오늘 회의 결과도 함께 가지고 가 주시겠어요\n",
      "*candidate: 그럼 오늘 회의 결과도 함께 가지고 오겠습니다\n",
      "\n",
      "*input    : 너무 늦지 않을까요  지금 본사로 보내는 것이 더 *blue: 0.8931539818068694 *-20\n",
      "*reference: 너무 늦지 않을까요  지금 본사로 보내는 것이 더 빠를 것 같아요\n",
      "*candidate: 너무 늦지 않을까요  지금 본사로 보내는 것이 더 빠를 것 같습니\n",
      "\n",
      "*input    : 행사 진행 아이디어가 있으면 *blue: 0.5475182535069453 *-21\n",
      "*reference: 행사 진행 아이디어가 있으면 지금 내주세요\n",
      "*candidate: 행사 진행 아이디어가 있으면 괜찮습니다\n",
      "\n",
      "*input    : 모든 직원에게 메일로 아이디어를 2개씩 *blue: 0.6431870218238024 *-22\n",
      "*reference: 모든 직원에게 메일로 아이디어를 2개씩 받으면 어떨까요\n",
      "*candidate: 모든 직원에게 메일로 아이디어를 2개씩 보내주세요\n",
      "\n",
      "*input    : 좋은 생각이네요  지금 당장 메일을 *blue: 0.7598356856515925 *-23\n",
      "*reference: 좋은 생각이네요  지금 당장 메일을 보내야겠어요\n",
      "*candidate: 좋은 생각이네요  지금 당장 메일을 보내드릴게\n",
      "\n",
      "*input    : 네  여러 명의 아이디어가 있으면 결과 *blue: 0.7013967267997694 *-24\n",
      "*reference: 네  여러 명의 아이디어가 있으면 결과도 더 좋겠죠\n",
      "*candidate: 네  여러 명의 아이디어가 있으면 결과도 좋으니까요\n",
      "\n",
      "*input    : 오후에는 회의 대신 교육프로그램이 예정되어 *blue: 0.5081327481546147 *-25\n",
      "*reference: 오후에는 회의 대신 교육프로그램이 예정되어있지 않았나요\n",
      "*candidate: 오후에는 회의 대신 교육프로그램이 예정되어 있습니다\n",
      "\n",
      "*input    : 어제 교육프로그램이 연기되었다는 메 *blue: 0.5081327481546147 *-26\n",
      "*reference: 어제 교육프로그램이 연기되었다는 메일을 받지 못했나요\n",
      "*candidate: 어제 교육프로그램이 연기되었다는 메일을 받았는데  어떻게\n",
      "\n",
      "*input    : 확인할 기회가 없었어요  언제로 연기 *blue: 0.41113361690051975 *-27\n",
      "*reference: 확인할 기회가 없었어요  언제로 연기됐는지 아시나요\n",
      "*candidate: 확인할 기회가 없었어요  언제로 연기할지 결정해야 해\n",
      "\n",
      "*input    : 아마 다음 주 화요일 일 거에요  *blue: 0.5873949094699213 *-28\n",
      "*reference: 아마 다음 주 화요일 일 거에요  다시 확인해볼게요\n",
      "*candidate: 아마 다음 주 화요일 일 거에요  수요일 오전에 회의\n",
      "\n",
      "*input    : 우리 제품은 어떤 방식으로 *blue: 0.5081327481546147 *-29\n",
      "*reference: 우리 제품은 어떤 방식으로 도쿄에 보내지나요\n",
      "*candidate: 우리 제품은 어떤 방식으로 판매하고 있나요\n",
      "\n",
      "*input    : 먼저 배로 도쿄 근처 항구까지 운반하고 그 후 *blue: 0.6132297420585351 *-30\n",
      "*reference: 먼저 배로 도쿄 근처 항구까지 운반하고 그 후 차를 이용합니다\n",
      "*candidate: 먼저 배로 도쿄 근처 항구까지 운반하고 그 후  다시 배를 타고 가나\n",
      "\n",
      "*input    : 그냥 서울에서 비행기로 바로 보내는 것이 *blue: 0.7013967267997694 *-31\n",
      "*reference: 그냥 서울에서 비행기로 바로 보내는 것이 낫지 않나요\n",
      "*candidate: 그냥 서울에서 비행기로 바로 보내는 것이 맞나요\n",
      "\n",
      "*input    : 비용이 많이 들어서 지금과 같은 *blue: 0.392814650900513 *-32\n",
      "*reference: 비용이 많이 들어서 지금과 같은 방법을 택했습니다\n",
      "*candidate: 비용이 많이 들어서 지금과 같은 속도로 가면 안 될 것\n",
      "\n",
      "*input    : 왜 오늘 오전에 실시된 *blue: 0.41113361690051975 *-33\n",
      "*reference: 왜 오늘 오전에 실시된 교육에 참여하지 않았나요\n",
      "*candidate: 왜 오늘 오전에 실시된 면접은 몇 분이\n",
      "\n",
      "*input    : 교육에 참여하는 것은 필수가 *blue: 0.6147881529512643 *-34\n",
      "*reference: 교육에 참여하는 것은 필수가 아니라 선택이었어요\n",
      "*candidate: 교육에 참여하는 것은 필수가 아니라  참여가 필수\n",
      "\n",
      "*input    : 그래요  그 내용을 어디서 *blue: 0.4347208719449914 *-35\n",
      "*reference: 그래요  그 내용을 어디서 확인할 수 있나요\n",
      "*candidate: 그래요  그 내용을 어디서 볼 수 있나\n",
      "\n",
      "*input    : 교육 안내 메일 하단에 *blue: 0.43012508513132625 *-36\n",
      "*reference: 교육 안내 메일 하단에 작은 글씨로 적혀있어요\n",
      "*candidate: 교육 안내 메일 하단에 보시면  저\n",
      "\n",
      "*input    : 창고에 있는 두 개의 박스 중 어떤 박 *blue: 0.7725505949016372 *-37\n",
      "*reference: 창고에 있는 두 개의 박스 중 어떤 박스를 배달해야 하죠\n",
      "*candidate: 창고에 있는 두 개의 박스 중 어떤 박스를 찾으세요\n",
      "\n",
      "*input    : 두 박스 모두 필요하니까 전부 *blue: 0.7013967267997694 *-38\n",
      "*reference: 두 박스 모두 필요하니까 전부 다 배달해야 해요\n",
      "*candidate: 두 박스 모두 필요하니까 전부 다 준비해주세요\n",
      "\n",
      "*input    : 저는 한 개의 박스만 배달 *blue: 0.345720784641941 *-39\n",
      "*reference: 저는 한 개의 박스만 배달하면 된다고 알고 있었는데요\n",
      "*candidate: 저는 한 개의 박스만 배달 가능한데  몇 개\n",
      "\n",
      "*input    : 그럼 제가 다시 한번 확인해볼게요  *blue: 0.5169731539571706 *-40\n",
      "*reference: 그럼 제가 다시 한번 확인해볼게요  잠시만 기다리세요\n",
      "*candidate: 그럼 제가 다시 한번 확인해볼게요  혹시 이 버튼\n",
      "\n",
      "*input    : 우리 잡지의 구독을 취소하는 가장 큰 *blue: 0.8408964152537145 *-41\n",
      "*reference: 우리 잡지의 구독을 취소하는 가장 큰 이유는 뭔가요\n",
      "*candidate: 우리 잡지의 구독을 취소하는 가장 큰 이유는 무엇인가요\n",
      "\n",
      "*input    : 정기구독 기간이 끝나면 다시 신청하지 않는 게 *blue: 0.7420884818558928 *-42\n",
      "*reference: 정기구독 기간이 끝나면 다시 신청하지 않는 게 제일 큽니다\n",
      "*candidate: 정기구독 기간이 끝나면 다시 신청하지 않는 게 좋겠어요\n",
      "\n",
      "*input    : 그렇다면 정기구독을 자동연장하는 것으로 바꾸 *blue: 1.0 *-43\n",
      "*reference: 그렇다면 정기구독을 자동연장하는 것으로 바꾸면 어떨까요\n",
      "*candidate: 그렇다면 정기구독을 자동연장하는 것으로 바꾸면 어떨까요\n",
      "\n",
      "*input    : 그렇게 한다면 비용 문제로 구독자들과 마찰이 *blue: 1.0 *-44\n",
      "*reference: 그렇게 한다면 비용 문제로 구독자들과 마찰이 생길 수도 있습니다\n",
      "*candidate: 그렇게 한다면 비용 문제로 구독자들과 마찰이 생길 수도 있습니다\n",
      "\n",
      "*input    : 우리 회사의 광고에 사용할 사진으로는 *blue: 0.7071067811865475 *-45\n",
      "*reference: 우리 회사의 광고에 사용할 사진으로는 어떤 것이 좋을까요\n",
      "*candidate: 우리 회사의 광고에 사용할 사진으로는 어떤 게 좋을까요\n",
      "\n",
      "*input    : 배경에 바다와 배들이 있는 *blue: 0.41113361690051975 *-46\n",
      "*reference: 배경에 바다와 배들이 있는 사진이 좋다고 생각해요\n",
      "*candidate: 배경에 바다와 배들이 있는 관광지가 제일 좋습니\n",
      "\n",
      "*input    : 곧 여름이니까 시원한 느낌의 배경을 *blue: 0.6147881529512643 *-47\n",
      "*reference: 곧 여름이니까 시원한 느낌의 배경을 고른 거군요\n",
      "*candidate: 곧 여름이니까 시원한 느낌의 배경을 원하신다면 괜\n",
      "\n",
      "*input    : 네  꼭 여름이 아니어도 우리 회사의 이미지와 *blue: 0.5900468726392808 *-48\n",
      "*reference: 네  꼭 여름이 아니어도 우리 회사의 이미지와 파란색이 잘 어울려요\n",
      "*candidate: 네  꼭 여름이 아니어도 우리 회사의 이미지와 잘 맞을 것 같\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 16:17:33,901 - gpt2-bleu - INFO - === *model:../model/gpt-2/kogpt-2-ft-0504/, *bleu_score:0.5469318501234257, * 처리시간: 7.118 초 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*input    : 회사 창고 중에 가장 큰 창고는 *blue: 0.6004287712485592 *-49\n",
      "*reference: 회사 창고 중에 가장 큰 창고는 어느 지역의 창고인가요\n",
      "*candidate: 회사 창고 중에 가장 큰 창고는 어디에 있나요\n",
      "\n",
      "*input    : 아마 양재에 있는 창고가 *blue: 0.36409302398068727 *-50\n",
      "*reference: 아마 양재에 있는 창고가 가장 크다고 알고 있어요\n",
      "*candidate: 아마 양재에 있는 창고가 비어있어서  그\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import statistics\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "#=============================================================================================\n",
    "# 테스트할 말뭉치 불러옴\n",
    "# => 실제 문장 뒤에 10글자는 제거한 test_sentences 문장을 만듬\n",
    "#######################################################\n",
    "corpus_path = \"../korpora/mycorpus/2_대화체.txt\"  # 말뭉치\n",
    "remove_num = 5 # 뒤에서 몇개 글자를 지울지 설정값\n",
    "#######################################################\n",
    "\n",
    "org_sentences = []\n",
    "test_sentences = []\n",
    "\n",
    "with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "      for line in f:\n",
    "            org_sentences.append(line.strip())  # strip() 계행문자 제거\n",
    "            test_sentences.append(line.strip()[:-(remove_num)])  # 뒤에 10개 문자를 제거함\n",
    "\n",
    "#print(f'*len:{len(org_sentences)}\\n')\n",
    "#print(f'*org:{org_sentences[0:5]}\\n')\n",
    "#print(f'*test:{test_sentences[0:5]}')\n",
    "\n",
    "start = time.time()\n",
    "#=============================================================================================\n",
    "# 실제 문장들을 입력하여, text generation 수행\n",
    "candidates, references, scores = get_bleu_scores(model=model,                       # GPT-2 모델\n",
    "                                                 tokenizer=tokenizer,               # Tokenizer\n",
    "                                                 device=device,                     # cuda:0, cpu \n",
    "                                                 sentences = org_sentences[0:50],   # 입력 문장들 list\n",
    "                                                 remove_token_len=remove_num,       # 뒤에서 제거할 토큰계수\n",
    "                                                 show_text=True)                    # True=input, candiate, reference, blue스코어등을 printf 함\n",
    "\n",
    "# bleu 스코어 평균을 구함    \n",
    "bleu_score = statistics.mean(scores)\n",
    "#=============================================================================================\n",
    "\n",
    "# 로그 출력\n",
    "logger.info(f'=== *model:{model_path}, *bleu_score:{bleu_score}, * 처리시간: {time.time() - start:.3f} 초 ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5016518-ad5e-42d4-a95a-2f33f1833b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# BLEU Score  예제 #1\\n\\nimport nltk.translate.bleu_score as bleu\\n\\n# 모델에서 출력한 값\\ncandidate = \"오늘은 날씨가 흐리고 비가 옵니다.\"\\n\\n# 실제 추정 값\\nreferences = [\\'내일은 날씨가 흐리고 비가 옵니다.\\', \\'오늘은 날씨가 좋고 비가 옵니다.\\', \\'오늘은 날씨가 흐리고 눈이 옵니다\\']\\n\\nbleu_score = bleu.sentence_bleu(list(map(lambda ref: ref.split(), references)),candidate.split())\\nprint(\\'*bleu_score:{}\\'.format(bleu_score))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# BLEU Score  예제 #1\n",
    "\n",
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "# 모델에서 출력한 값\n",
    "candidate = \"오늘은 날씨가 흐리고 비가 옵니다.\"\n",
    "\n",
    "# 실제 추정 값\n",
    "references = ['내일은 날씨가 흐리고 비가 옵니다.', '오늘은 날씨가 좋고 비가 옵니다.', '오늘은 날씨가 흐리고 눈이 옵니다']\n",
    "\n",
    "bleu_score = bleu.sentence_bleu(list(map(lambda ref: ref.split(), references)),candidate.split())\n",
    "print('*bleu_score:{}'.format(bleu_score))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be352921-fd22-42cd-be87-96d54dee290a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# BLEU Score  예제 #2\\n\\nimport statistics\\nfrom nltk.translate.bleu_score import sentence_bleu\\n\\nscores = []\\nfor i in range(len(references)):\\n    references_list = []\\n    references_list.append(references[i])  #references는 리스트로 변환해야 함\\n    candidate = candidates[i]\\n    inputtext = inputs[i]\\n    \\n    ref = list(map(lambda ref: ref.split(), references_list))\\n    bleu = sentence_bleu(ref, candidate.split())\\n    \\n    print(f\"*input: {inputtext} *blue: {bleu}\")\\n    print(f\"*reference: {references_list[0]}\")\\n    print(f\"*candidate: {candidate}\\n\")\\n    \\n    scores.append(bleu)\\n\\n# bleu 스코어 평균을 구함    \\nbleu_score = statistics.mean(scores)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# BLEU Score  예제 #2\n",
    "\n",
    "import statistics\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "scores = []\n",
    "for i in range(len(references)):\n",
    "    references_list = []\n",
    "    references_list.append(references[i])  #references는 리스트로 변환해야 함\n",
    "    candidate = candidates[i]\n",
    "    inputtext = inputs[i]\n",
    "    \n",
    "    ref = list(map(lambda ref: ref.split(), references_list))\n",
    "    bleu = sentence_bleu(ref, candidate.split())\n",
    "    \n",
    "    print(f\"*input: {inputtext} *blue: {bleu}\")\n",
    "    print(f\"*reference: {references_list[0]}\")\n",
    "    print(f\"*candidate: {candidate}\\n\")\n",
    "    \n",
    "    scores.append(bleu)\n",
    "\n",
    "# bleu 스코어 평균을 구함    \n",
    "bleu_score = statistics.mean(scores)\n",
    "'''   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
