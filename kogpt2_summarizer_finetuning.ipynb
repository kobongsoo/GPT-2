{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf1110b-470b-4106-aa7b-3bb9954ea230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../log/bwdataset_2022-05-09.log\n",
      "logfilepath:../log/qnadataset_2022-05-09.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "cuda:0\n",
      "logfilepath:../log/gpt2-ft_2022-05-09.log\n"
     ]
    }
   ],
   "source": [
    "#====================================================================================================\n",
    "# kogpt2 를 이용해 훈련한 모델 추론(생성) 요약(abstractive summarization) 훈련 예시\n",
    "# => \n",
    "# => https://www.nbshare.io/notebook/764386829/Amazon-Review-Summarization-Using-GPT-2-And-PyTorch/\n",
    "#\n",
    "# => text generation 모델이므로  acc 구하는 것은 의미 없음(*따라서 train loss, val loss 만 구함)\n",
    "#\n",
    "# => 여기서는 훈련할때 요약할 문장과 요약 문장사이에 구분자 토큰을 <segment>로 지정하였음.(해당 토큰은 다른것으로 지정하여 훈련시켜도 됨)\n",
    "@\n",
    "# [훈련 dataset]\n",
    "# => input_ids = '요약할 문장<segment>요약문</s>'    : <segment>토큰은 요약할 문장과 요약문 사이 구분자로 대체 가능함\n",
    "# => labels = input_ids와 동일\n",
    "#\n",
    "# [추론(생성) 요약(abstractive summarization) 훈련 과정]\n",
    "# \n",
    "# 1. gpt-2 모델 선언(GPT2LMHeadModel), tokenizer 선언(PreTrainedTokenizerFast)\n",
    "# 2. '요약할 문장+구분token(<summarize>)+요약문+<eos>토큰' 식으로 된 훈련 dataset 생성\n",
    "# 3. 모델에 input_ids, lables 을 입력하여 훈련 시킴\n",
    "#====================================================================================================\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import time\n",
    "from myutils import GPU_info, seed_everything, mlogging, SaveBERTModel, AccuracyForMLM\n",
    "from summarizer import TransformerSummarizer\n",
    "model_path='../model/gpt-2/kogpt-2/'\n",
    "#model_path='skt/kogpt2-base-v2'\n",
    "#model_path = \"gpt2-medium\"\n",
    "\n",
    "# 출력\n",
    "OUTPATH = '../model/gpt-2/kogpt-2-ft-summarizer-0504/'\n",
    "\n",
    "device = GPU_info()\n",
    "print(device)\n",
    "\n",
    "#seed 설정\n",
    "seed_everything(222)\n",
    "\n",
    "#logging 설정\n",
    "logger =  mlogging(loggername=\"gpt2-ft\", logfilename=\"../log/gpt2-ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63aad3da-2f1b-4574-b907-290e54860a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약문 corpus 파일 열기 \n",
    "corpus_path = \"../korpora/mycorpus/newspaper.csv\"\n",
    "with open(corpus_path, \"r\") as reviews_raw:\n",
    "    reviews = reviews_raw.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "076f092e-6cee-4c3c-b8c4-f09582aec92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['충주시는 민간보조사업의 증가와 보조금 집행관리에 대한 부당 행위가 증가함에따라 15일부터 25일까지 보조금 실태를 파악한 후 8월15일까지 세부감사를 진행  운영실태 전반에 대한 자체 감사를 실시할 계획이라고 밝혔다 ,충주시  민간지원 보조사업 대형축제 운영 감사 돌입\\n',\n",
       " '국무조정실은 8일 오후 대전시청에서  대전지역 규제혁신 현장간담회 를 열고 대전과 충남에 취약한 뿌리산업 육성방안으로 규제개선을 논의하였으며  관계자는 기업과 국민들이 체감할 수 있는 규제개선이 이루어지도록 최대한 노력할 것이라고 밝혔다 ,대전도 뿌리산업 특화단지 길 열린다   국무조정실 규제개선키로\\n',\n",
       " '중국 경제일간지 21세기경제보도는 중국 대형 생명보험사인 차이나라이프가  차이나라이프 중흥 이라는 전략적 목표를 세우고 비즈니스 중심의 조직 시스템 구축과 인터넷 생명보험회사 설립에 착수 중이라고 17일 보도하였다 ,중국 생보사 차이나라이프  인터넷 보험사 설립 추진\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707e85e0-56cb-4126-aa7e-8c0467d62eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3091\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72731ac2-985c-4d3a-bb5c-36e38ac7c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews 문장은 text, 요약문 식으로 되어 있다.\n",
    "# => 이 구분자 , 를 <summarize> 로 변경함.(*<summarize> 토큰이 아니라, 다른 토큰을 지정해도 됨)\n",
    "reviews = [review.replace(\",\", \"<summarize>\") for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae098913-5845-419e-b823-4e69904222cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'국무조정실은 8일 오후 대전시청에서  대전지역 규제혁신 현장간담회 를 열고 대전과 충남에 취약한 뿌리산업 육성방안으로 규제개선을 논의하였으며  관계자는 기업과 국민들이 체감할 수 있는 규제개선이 이루어지도록 최대한 노력할 것이라고 밝혔다 <summarize>대전도 뿌리산업 특화단지 길 열린다   국무조정실 규제개선키로\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "118c7702-7c8a-4e5b-8074-36c07997911b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.62924619864122"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 총 단어의 길이를 얻어옴\n",
    "avg_length = sum([len(review.split()) for review in reviews])/len(reviews)\n",
    "avg_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e17114-82ab-4e8e-aa7c-c0a65981e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 단어의 길이보다 길게 설정\n",
    "max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0154b5d0-18f0-4bea-82f0-6c2415c4c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer 로딩 \n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_path,\n",
    "                                                   bos_token='</s>',\n",
    "                                                   eos_token='</s>',\n",
    "                                                   unk_token='<unk>',\n",
    "                                                   pad_token='<pad>',\n",
    "                                                   mask_token='<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06240c79-1531-4eab-a43f-5c608cbaabbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 정의 하고, embedding size를 tokenizer 사이즈만큼 조정\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e51fbc0f-ccc4-4891-aac2-0b08aebfc797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9724, 457, 459, 10473, 9837, 21049, 443, 405]\n",
      "***<summarize> token len:8\n"
     ]
    }
   ],
   "source": [
    "# ** 구분자  <summarize> 토큰의 길이를 얻어옴\n",
    "print(tokenizer.encode(\"<summarize>\"))\n",
    "extra_length = len(tokenizer.encode(\"<summarize>\"))\n",
    "print(f'***<summarize> token len:{extra_length}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6015caf8-b943-4897-ab70-01888598eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 설정 함수\n",
    "class summarizeDataset(Dataset):\n",
    "    def __init__(self, tokenizer, sentences, max_len, summarize_token_len):\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.eos = self.tokenizer.eos_token\n",
    "        self.eos_id = self.tokenizer.eos_token_id\n",
    "        self.sentences = sentences\n",
    "        self.summarize_token_len = summarize_token_len\n",
    "        self.result = []\n",
    "        \n",
    "        for sentence in self.sentences:\n",
    "            # 한 문장 뒤에 </s>(EOS 토큰) 추가\n",
    "            tokenized = self.tokenizer.encode(sentence + self.eos)\n",
    "            #print(tokenized)\n",
    "            # padd \n",
    "            padded = self.pad_truncate(tokenized)\n",
    "            \n",
    "            # 출력\n",
    "            self.result.append(torch.tensor(padded))\n",
    "           \n",
    "    def __len__(self):\n",
    "        return len(self.result)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return self.result[item]\n",
    "    \n",
    "    # padd 붙이는 함수\n",
    "    def pad_truncate(self, name):\n",
    "        \n",
    "        # name_length는 총 name 길이에서 - summzrize_token 길이를 뺀 길이가 됨\n",
    "        # (예: name 길이 = 110 이면 name_length = 110 - 8 = 102)\n",
    "        name_length = len(name) - self.summarize_token_len\n",
    "        \n",
    "        # name 길이 < 100 작으면, 뒤에 108개까지는 eos_id(1)로 padd 붙임\n",
    "        if name_length < self.max_len:\n",
    "            difference = self.max_len - name_length\n",
    "            result = name + [self.eos_id] * difference\n",
    "        # name 길이 > 100 크면, 100+7 까지만 name 값 출력하고, 뒤에 eos_id(1) 붙임 = 총 108개가 됨\n",
    "        elif name_length > self.max_len:\n",
    "            result = name[:self.max_len + self.summarize_token_len - 1]+[self.eos_id]\n",
    "        else:\n",
    "            result = name\n",
    "        \n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9086b2c1-8580-4609-b34b-9c4c857a4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 만듬\n",
    "dataset = summarizeDataset(tokenizer, reviews, max_length, extra_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa1e5cf9-562c-43bd-9db9-8d1e387a7406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14932, 13305, 16428, 16308, 21734, 13899,  7888, 29718,   739, 13899,\n",
       "         9635, 17143, 25002, 16380,  6826,  7191,  8765, 36055, 20759,  9026,\n",
       "        12391, 27775,  8022,  9499, 16455, 13961, 10258, 16891,  7607, 21609,\n",
       "        17143,  6841, 10402, 13564, 15423,   739,  9804,  9599, 50865,  9888,\n",
       "         9136, 48262,  8705,  9025,  9080, 17143,  6841, 10886,  9442, 25682,\n",
       "        19226, 10805,  8705, 11839, 28296,  7182,  9724,   457,   459, 10473,\n",
       "         9837, 21049,   443,   405, 10238,  7235, 13961, 10258,  9125,  8756,\n",
       "        18081,  9367, 13363,  7182,   739,   739, 14932, 13305,  7892, 17143,\n",
       "        32931,  8511,  7426,   375,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "499222e0-0c3b-4102-ab3c-252d652560f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 생성 \n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e04cc47a-6ad2-4550-bc51-da52fe3c8e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8dc8e391df435c97047d7ad20bdaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e00707c34b2430c9366c66264cf8ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 09:53:04,780 - gpt2-ft - INFO - [Epoch 1/2] Iteration 9 -> Train Loss: 5.2991\n",
      "2022-05-09 09:53:06,660 - gpt2-ft - INFO - [Epoch 1/2] Iteration 18 -> Train Loss: 2.6479\n",
      "2022-05-09 09:53:08,595 - gpt2-ft - INFO - [Epoch 1/2] Iteration 27 -> Train Loss: 2.3757\n",
      "2022-05-09 09:53:10,535 - gpt2-ft - INFO - [Epoch 1/2] Iteration 36 -> Train Loss: 2.3654\n",
      "2022-05-09 09:53:12,415 - gpt2-ft - INFO - [Epoch 1/2] Iteration 45 -> Train Loss: 2.3134\n",
      "2022-05-09 09:53:14,278 - gpt2-ft - INFO - [Epoch 1/2] Iteration 54 -> Train Loss: 2.2806\n",
      "2022-05-09 09:53:16,168 - gpt2-ft - INFO - [Epoch 1/2] Iteration 63 -> Train Loss: 2.2724\n",
      "2022-05-09 09:53:17,928 - gpt2-ft - INFO - [Epoch 1/2] Iteration 72 -> Train Loss: 2.1756\n",
      "2022-05-09 09:53:19,756 - gpt2-ft - INFO - [Epoch 1/2] Iteration 81 -> Train Loss: 2.2154\n",
      "2022-05-09 09:53:21,673 - gpt2-ft - INFO - [Epoch 1/2] Iteration 90 -> Train Loss: 2.2204\n",
      "2022-05-09 09:53:23,933 - bwpdataset - INFO - ==> save_model : ../model/gpt-2/kogpt-2-ft-summarizer-0504/batch:32-ep:2-lr:0.000030000-5m9d-9:53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c224e967044a02ab486a2aa967e85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 09:53:24,583 - gpt2-ft - INFO - [Epoch 2/2] Iteration 99 -> Train Loss: 2.2046\n",
      "2022-05-09 09:53:26,502 - gpt2-ft - INFO - [Epoch 2/2] Iteration 108 -> Train Loss: 1.9773\n",
      "2022-05-09 09:53:28,383 - gpt2-ft - INFO - [Epoch 2/2] Iteration 117 -> Train Loss: 2.0098\n",
      "2022-05-09 09:53:30,326 - gpt2-ft - INFO - [Epoch 2/2] Iteration 126 -> Train Loss: 2.0831\n",
      "2022-05-09 09:53:32,202 - gpt2-ft - INFO - [Epoch 2/2] Iteration 135 -> Train Loss: 2.0460\n",
      "2022-05-09 09:53:34,079 - gpt2-ft - INFO - [Epoch 2/2] Iteration 144 -> Train Loss: 1.9574\n",
      "2022-05-09 09:53:35,976 - gpt2-ft - INFO - [Epoch 2/2] Iteration 153 -> Train Loss: 2.0478\n",
      "2022-05-09 09:53:37,856 - gpt2-ft - INFO - [Epoch 2/2] Iteration 162 -> Train Loss: 1.9989\n",
      "2022-05-09 09:53:39,836 - gpt2-ft - INFO - [Epoch 2/2] Iteration 171 -> Train Loss: 2.0246\n",
      "2022-05-09 09:53:41,709 - gpt2-ft - INFO - [Epoch 2/2] Iteration 180 -> Train Loss: 1.9880\n",
      "2022-05-09 09:53:43,598 - gpt2-ft - INFO - [Epoch 2/2] Iteration 189 -> Train Loss: 2.0102\n",
      "2022-05-09 09:53:45,295 - bwpdataset - INFO - ==> save_model : ../model/gpt-2/kogpt-2-ft-summarizer-0504/batch:32-ep:2-lr:0.000030000-5m9d-9:53\n"
     ]
    }
   ],
   "source": [
    "# 훈련 시작 \n",
    "\n",
    "##################################################\n",
    "epochs = 2            # epochs\n",
    "learning_rate = 3e-5  # 학습률\n",
    "##################################################\n",
    "\n",
    "# optimizer 적용\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                 lr=learning_rate, \n",
    "                 eps=1e-8) # 0으로 나누는 것을 방지하기 위한 epsilon 값(10^-6 ~ 10^-8 사이 이값 입력합)\n",
    "\n",
    "# 총 훈련과정에서 반복할 스탭\n",
    "total_steps = len(train_loader)*epochs\n",
    "warmup_steps = total_steps * 0.1 #10% of train data for warm-up\n",
    "\n",
    "# 손실률 보여줄 step 수\n",
    "p_itr = int(len(train_loader)*0.1)  \n",
    "    \n",
    "# step마다 모델 저장\n",
    "save_steps = int(total_steps * 0.5)\n",
    "    \n",
    "# 스캐줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=warmup_steps, \n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "itr = 1\n",
    "\n",
    "total_loss = 0\n",
    "list_train_loss = []\n",
    "\n",
    "# 그래디언트 초기화(*set_to_none=True 로 설정하면, 그래디언트 업데이트시, 쓰기작업만 수행되어 속도가 빨라진다)\n",
    "model.zero_grad(set_to_none=True)\n",
    "for epoch in tqdm(range(epochs)):\n",
    "\n",
    "    model.train() # 훈련모드로 변환\n",
    "    for data in tqdm(train_loader):\n",
    "        model.zero_grad(set_to_none=True)# 그래디언트 초기화(*set_to_none=True 로 설정하면, 그래디언트 업데이트시, 쓰기작업만 수행되어 속도가 빨라진다)\n",
    "        \n",
    "        # 입력 값 설정\n",
    "        input_ids = data.to(device)\n",
    "        labels = data.to(device)\n",
    "        #print('Labels:{}'.format(labels))\n",
    "        \n",
    "        # 모델 실행\n",
    "        outputs = model(input_ids=input_ids, \n",
    "                        labels=labels)\n",
    "        \n",
    "       \n",
    "        # 출력값 loss,logits를 outputs에서 얻어옴\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        #print('Loss:{}, logits:{}'.format(loss, logits))\n",
    "        \n",
    "        # logits_shape: torch.Size([32, 68, 51200])\n",
    "        # => batch_size, sequence_max_len, token_len\n",
    "        #print(f'logits_shape: {logits.shape}')                    \n",
    "        \n",
    "        # optimizer 과 scheduler 업데이트 시킴\n",
    "        loss.backward()   # backward 구함\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)   # 그래디언트 클리핑 (gradient vanishing이나 gradient exploding 방지하기 위한 기법)\n",
    "        optimizer.step()  # 가중치 파라미터 업데이트(optimizer 이동)\n",
    "        scheduler.step()  # 학습률 감소\n",
    "        \n",
    "        # ***further pretrain 에는 손실률 계산을 넣지 않음\n",
    "        # 정확도 계산하는 부분은 no_grade 시켜서, 계산량을 줄임.\n",
    "        \n",
    "        # => torch.no_grad()는 gradient을 계산하는 autograd engine를 비활성화 하여 \n",
    "        # 필요한 메모리를 줄이고, 연산속도를 증가시키는 역활을 함\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # 손실률 계산\n",
    "            total_loss += loss.item()\n",
    "                \n",
    "            #===========================================\n",
    "            # 정확도(Accurarcy) 계산\n",
    "            #correct = AccuracyForMLM(logits, labels, attention_mask)           \n",
    "            #total_correct += correct.sum().item() \n",
    "            #total_len += attention_mask.sum().item()\n",
    "            #=========================================\n",
    "     \n",
    "            # 주기마다 test(validataion) 데이터로 평가하여 손실류 계산함.\n",
    "            if itr % p_itr == 0:\n",
    "                \n",
    "                train_loss = total_loss/p_itr\n",
    "                                   \n",
    "                logger.info('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}'.format(epoch+1, epochs, itr, train_loss))\n",
    "                     \n",
    "                list_train_loss.append(train_loss)\n",
    "                 \n",
    "                # 변수들 초기화    \n",
    "                total_loss = 0\n",
    "                ####################################################################\n",
    "            if itr % save_steps == 0:\n",
    "                #전체모델 저장\n",
    "                SaveBERTModel(model, tokenizer, OUTPATH, epochs, learning_rate, batch_size)\n",
    "\n",
    "        itr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f03d6fbf-bc8a-49da-b2b3-732654e1fb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 09:59:51,958 - bwpdataset - INFO - ==> save_model : ../model/gpt-2/kogpt-2-ft-summarizer-0504/batch:32-ep:2-lr:0.000030000-5m9d-9:59\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "SaveBERTModel(model, tokenizer, OUTPATH, epochs, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a2e3f43-a44f-4d02-b1a3-289a4d7e727c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프로 loss 표기\n",
    "#!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(list_train_loss, label='Train Loss')\n",
    "#plt.plot(list_validation_acc, label='Eval Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b5bebde9-ddec-48b8-b822-19e40967a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론시 topk 알고리즘 사용\n",
    "def topk(probs, n=9):\n",
    "    probs = torch.softmax(probs, dim=-1)\n",
    "    \n",
    "    tokensProb, topIx = torch.topk(probs, k=n)\n",
    "    tokensProb = tokensProb / torch.sum(tokensProb)\n",
    "    \n",
    "    tokensProb = tokensProb.cpu().detach().numpy()\n",
    "    \n",
    "    choice = np.random.choice(n,1,p=tokensProb)\n",
    "    tokenId = topIx[choice][0]\n",
    "    \n",
    "    return int(tokenId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "568582f6-de63-43f0-8310-6126b4e07165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize 추론 처리 함수 \n",
    "def model_infer(model, tokenizer, review, max_length=15):\n",
    "    review_encoded = tokenizer.encode(review)\n",
    "    result = review_encoded\n",
    "    initial_input = torch.tensor(review_encoded).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(initial_input)\n",
    "        \n",
    "        logits = outputs.logits[0,-1]\n",
    "        print(logits.shape)  # embedding 계수 출력됨\n",
    "        #result.append(topk(logits))\n",
    "        #print(result)\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            input = torch.tensor(result).unsqueeze(0).to(device)\n",
    "            outputs = model(input)\n",
    "            logits = outputs.logits[0,-1]\n",
    "            res_id = topk(logits)\n",
    "            \n",
    "            if res_id == tokenizer.eos_token_id:\n",
    "                return tokenizer.decode(result)\n",
    "            else:\n",
    "                result.append(res_id)\n",
    "                \n",
    "    return tokenizer.decode(result)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e396e2d-a08b-4a83-b18f-b1a3b0c53d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51200])\n",
      "여름철 태양열 싼 지역에 태양광 보급\n"
     ]
    }
   ],
   "source": [
    "# A review is initially fed to the model.\n",
    "# A choice from the top-k choices is selected.\n",
    "# The choice is added to the summary and the current sequence is fed to the model.\n",
    "# Repeat steps 2 and 3 until either max_len is achieved or the EOS token is generated.\n",
    "\n",
    "body = '''\n",
    "전남도는 청정하고 안전한 신재생에너지 보급 확산을 위해 추진하는 ‘2022년 신재생에너지 보급 주택지원사업’ 참여 가구를 9일부터 6월 3일까지 모집한다고 밝혔다.\n",
    "신재생에너지 보급 주택지원사업은 주택에 태양광, 태양열, 연료전지, 지열 등 신재생에너지 설비를 설치하는 도민에게 정부 지원금 외에 도비와 시군비를 추가로 지원하는 사업이다.\n",
    "사업 대상자로 선정되면 설치비 자부담분(50%)의 40%를 도비와 시군비로 지원하기 때문에 비용부담을 줄일 수 있다.\n",
    "전남도는 올해 지방비 17억원을 들여 1600여 가구에 신재생에너지 설비를 보급할 계획이다.\n",
    "지원을 바라는 주택 소유자는 한국에너지공단 그린홈 누리집에서 회원가입 후 공단에 등록한 참여업체를 지정해 신청하면 된다.\n",
    "지방비 보조금은 한국에너지공단의 최종 사업 승인 후 해당 시군에 지원 신청을 하면 예산 범위에서 선착순 지원한다.\n",
    "자세한 사항은 한국에너지공단 광주전남지역본부, 전남도 에너지신산업과, 시군 에너지업무 담당 부서로 문의하면 된다.\n",
    "주택에 3KW 태양광 설비를 설치하면 총 설치비 516만원 중 국비 258만원과 추가로 지방비 103만원을 지원하기 때문에 155만원만 자부담하면 된다.\n",
    "3KW 태양광 설비를 설치한 가구는 월 4만5000원씩 연간 54만원의 전기요금을 절감할 수 있다.\n",
    "'''\n",
    "\n",
    "output = model_infer(model, tokenizer, body + \"<summarize>\", 100)\n",
    "#print(output)\n",
    "\n",
    "summary = output.split(\"<summarize>\")[1].strip()\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
