{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3fa0a4-6b48-44be-ab07-7d6c78ed437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logfilepath:../log/bwdataset_2022-05-09.log\n",
      "logfilepath:../log/qnadataset_2022-05-09.log\n",
      "True\n",
      "device: cuda:0\n",
      "cuda index: 0\n",
      "gpu 개수: 1\n",
      "graphic name: NVIDIA A30\n",
      "cuda:0\n",
      "logfilepath:../log/gpt2-summarize-test_2022-05-09.log\n"
     ]
    }
   ],
   "source": [
    "#====================================================================================================\n",
    "# kogpt2 를 이용해 훈련한 모델 추론(생성) 요약(abstractive summarization) 테스트 예시\n",
    "# => \n",
    "# => https://www.nbshare.io/notebook/764386829/Amazon-Review-Summarization-Using-GPT-2-And-PyTorch/\n",
    "#\n",
    "# [테스트 데이터]\n",
    "# => input_ids = 요약할 문장<segment>\n",
    "# 여기서 테스트 모델은 kogpt2 pretrain 모델에, '요약할문장<segment>요약문장</s>' 식에 데이터 셋을 가지고,\n",
    "# fine-tuning한 모델임. 따라서 반드시, '요약할 문장<segment>' 식으로 입력을 해야 함\n",
    "# <segment> 토큰은 훈련할때 임의로 변경할수 있음.\n",
    "\n",
    "# [추론(생성) 요약(abstractive summarization) 추론 과정]\n",
    "# \n",
    "# 1. gpt-2 모델 선언(GPT2LMHeadModel), tokenizer 선언(PreTrainedTokenizerFast)\n",
    "# 2. '요약할 문장+구분token(<summarize>) 를 모델에 입력\n",
    "# 3. logits 얻음 : <summarize> 다음에 올 단어들의 확률분포(총 embedding 단어계수 배열이 출력됨)\n",
    "# 4. top=k 알고리즘으로 logits중에서 확률이 높은 상위 k계 단어 중에서, 랜덤한 1개의 단어 선택\n",
    "# 5. 선택한 단어를 다시 모델에 입력 \n",
    "# 6. 출력된 logits에서 다시 확률이 가장높은 상위 k 단어중에서, 랜덤한 1개의 단어 선택\n",
    "# 7 . 5.6 과정을 반복(단어의 계수가 max_len 이될때까지 혹은 eos 토큰이 출력될때까지)\n",
    "#====================================================================================================\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, RandomSampler, SequentialSampler \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import time\n",
    "from myutils import GPU_info, seed_everything, mlogging\n",
    "\n",
    "model_path='../model/gpt-2/kogpt-2-ft-summarizer-0509/'\n",
    "\n",
    "\n",
    "device = GPU_info()\n",
    "print(device)\n",
    "\n",
    "#seed 설정\n",
    "seed_everything(222)\n",
    "\n",
    "#logging 설정\n",
    "logger =  mlogging(loggername=\"gpt2-summarize-test\", logfilename=\"../log/gpt2-summarize-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bfc027-9333-47c6-a87e-a6044cc59d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(51200, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer 로딩 \n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_path,\n",
    "                                                   bos_token='</s>',\n",
    "                                                   eos_token='</s>',\n",
    "                                                   unk_token='<unk>',\n",
    "                                                   pad_token='<pad>',\n",
    "                                                   mask_token='<mask>')\n",
    "# 모델 로딩\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e395d5-1b6c-4b36-85ac-7f2bb2c70973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 n 만큼 단어들을 선택함.\n",
    "def topk(probs, n=9):\n",
    "    probs = torch.softmax(probs, dim=-1)  # 0~1까지 모든 embedding 단어들의 확률값 구함\n",
    "    \n",
    "    # 상위 k 계수 단어들의 확률값을 구함\n",
    "    tokensProb, topIx = torch.topk(probs, k=n)\n",
    "    tokensProb = tokensProb / torch.sum(tokensProb)\n",
    "    \n",
    "    tokensProb = tokensProb.cpu().detach().numpy()\n",
    "    \n",
    "    # 랜덤하게 k 단어들에 대해 1개의 단어를 리턴 함\n",
    "    choice = np.random.choice(n,1,p=tokensProb)\n",
    "    tokenId = topIx[choice][0]\n",
    "    \n",
    "    return int(tokenId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fd3989b-3525-4190-9dbd-1cf614096426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize 추론 함수\n",
    "def model_infer(model, \n",
    "                tokenizer, \n",
    "                review, \n",
    "                max_length=15,  # 최대 요약문 출력 단어수\n",
    "                topk_num=9,     # 임베딩 중 상위 k 선택 항목수(*10으로 지정하면, 10개의 단어중 랜덤한 1단어가 다음 단어로 출력됨)\n",
    "                eos_stop=True): # true = eos 토큰이 출력되면 요약문 생성 종료, false=max_length 만큼 무조건 요약문 생성\n",
    "    \n",
    "    # tokenizer 로 '요약할 문장<segment>' encode 하여 id 출력\n",
    "    review_encoded = tokenizer.encode(review)\n",
    "   \n",
    "    # result = 요약할 문장<segment>\n",
    "    result = review_encoded\n",
    "    #print(f'result:{result}')\n",
    "    print(f'result len:{len(result)}') \n",
    "    \n",
    "    # tokenizer된 id를 1차원으로 만듬\n",
    "    initial_input = torch.tensor(review_encoded).unsqueeze(0).to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        \n",
    "        # 1차원으로 된 요약할 문장<segment> token 모델에 입력\n",
    "        outputs = model(initial_input)\n",
    "        \n",
    "        # outputs에는 embedding 계수가 출력됨\n",
    "        logits = outputs.logits[0,-1]\n",
    "        print(f'logits.shape:{logits.shape}')  \n",
    "       \n",
    "        # result = 요약할 문장<segment> + embedding 계수중 상위 topk_num 계중 랜덤한 1개 단어\n",
    "        res_id = topk(logits, topk_num)\n",
    "        print(f'res_id:{res_id}-{tokenizer.decode(res_id)}')\n",
    "        result.append(res_id)\n",
    "        \n",
    "        #print(f'out: result:{result}')\n",
    "        print(f'out: result len:{len(result)}')\n",
    "     \n",
    "        # max_length 만큼 돌면서, \n",
    "        for _ in range(max_length):\n",
    "            # 앞에 result 값이 들어감\n",
    "            input = torch.tensor(result).unsqueeze(0).to(device)\n",
    "            #print(f'input:{input}')\n",
    "                \n",
    "            # 다음 단어 출력 \n",
    "            outputs = model(input)\n",
    "            logits = outputs.logits[0,-1]\n",
    "            \n",
    "            # 상위 topk_num 계중 랜덤한 1개 단어 선택\n",
    "            res_id = topk(logits, topk_num)\n",
    "            print(f'res_id:{res_id}-{tokenizer.decode(res_id)}')\n",
    "            \n",
    "            # EOS 토큰을 만날때까지 계속 max_length 만큼 돔\n",
    "            if eos_stop:\n",
    "                if res_id == tokenizer.eos_token_id:\n",
    "                    return tokenizer.decode(result)\n",
    "                else:\n",
    "                    result.append(res_id)\n",
    "            else:\n",
    "                result.append(res_id)\n",
    "            \n",
    "    return tokenizer.decode(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "866e7e88-c8fe-4283-8244-24bf12f02409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result len:131\n",
      "logits.shape:torch.Size([51200])\n",
      "res_id:8367-청\n",
      "out: result len:132\n",
      "res_id:8066-와\n",
      "res_id:7198-대\n",
      "res_id:20508-도심\n",
      "res_id:14499-순환\n",
      "res_id:28147-버스\n",
      "res_id:31957-노선\n",
      "res_id:11454-신설\n",
      "res_id:739-\n",
      "res_id:739-\n",
      "res_id:739-\n",
      "res_id:739-\n",
      "res_id:26074-시내\n",
      "res_id:12942-접근\n",
      "res_id:7799-성\n",
      "res_id:10416-강화\n",
      "res_id:375-\n",
      "\n",
      "res_id:1-</s>\n",
      "청와대 도심 순환버스 노선 신설     시내 접근성 강화\n"
     ]
    }
   ],
   "source": [
    "# A review is initially fed to the model.\n",
    "# A choice from the top-k choices is selected.\n",
    "# The choice is added to the summary and the current sequence is fed to the model.\n",
    "# Repeat steps 2 and 3 until either max_len is achieved or the EOS token is generated.\n",
    "\n",
    "body = '''\n",
    "청와대 개방을 맞아 청와대에서 시청역과 남산타워, 충무로역을 잇는 순환버스 노선이 신설됐다. \n",
    "청와대 진입로에 위치했던 검문소는 철거되고, 급경사가 많은 백악정~북악산 등산로 구간에는 데크와 계단이 설치된다. \n",
    "청와대 사랑채에서 시작하는 야간 경관 해설 프로그램 등 문화행사도 진행된다.\n",
    "이달 10일 청와대 개방을 앞두고 서울시는 청와대 인근 교통체계 개편과 문화행사 기획을 담은 종합지원대책을 발표했다. \n",
    "청와대 개방 행사가 열리는 10일부터 22일까지 1일 평균 관광객이 4만명가량 증가할 것이라는 계산이다\n",
    "'''\n",
    "\n",
    "output = model_infer(model, tokenizer, body + \"<summarize>\", max_length = 20, topk_num=10, eos_stop=True)\n",
    "#print(output)\n",
    "\n",
    "# 출력 output에는 body<summarize>요약문 식으로 출력되므로, 여기서는 <summarize> 토크 다음 요약문만 출력 함\n",
    "summary = output.split(\"<summarize>\")[1].strip()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61fff770-938c-41cc-9e27-97cec74fc948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전\n",
      "남도\n",
      "\n",
      "신재\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(8187))\n",
    "print(tokenizer.decode(10347))\n",
    "print(tokenizer.decode(739))\n",
    "print(tokenizer.decode(34327))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67cfc9a-69d6-41be-970e-0336197f1a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
